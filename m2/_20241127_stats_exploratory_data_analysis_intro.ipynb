{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec79ffca",
   "metadata": {},
   "source": [
    "# Introduction to Statistics\n",
    "\n",
    "- __Theoretical perspective:__ Statistics is primarily an applied branch of mathematics, which tries to make sense of observations in the real world. \n",
    "\n",
    "- __Practical perspective:__ Statistics can help us make decisions in uncertain situations.\n",
    "\n",
    "--\n",
    "\n",
    "`Statistics and Probability are not the same. Probability theory enables us to find the consequences of a given ideal world, while statistical theory enables us to to measure the extent to which our world is ideal`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be5fa8",
   "metadata": {},
   "source": [
    "## StatisticS\n",
    "\n",
    "- __The Field of Statistics:__ the study and practice of collecting and analyzing data.\n",
    "\n",
    "- __Statistics:__ facts about, or summaries of data.\n",
    "\n",
    "\n",
    "--\n",
    "\n",
    "\n",
    "- __Descriptive statistics (sample):__ describe what the data shows, making the data we get more digestable eventhough we lose information about individual data point.\n",
    "\n",
    "- __Inferential statistics (population):__ allow us to make conclusions that extend beyond the data (i.e.: testing an hyphotesis!) and help us make decisions about data when there's uncertainty.\n",
    "\n",
    "--\n",
    "\n",
    "`Statistics works as a proxy which is something related to what we want to measure, but isn't exactly what we want to measure`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994a6047",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "It may seems counterintuitive, but classical statistics focused almost exclusively on _inference_ (i.e.: a complex set of procedures for drawing conclusions about large populations based on small samples). However, with the ready availability of computing power and expressive data analysis software, exploratory data analysis (a.k.a.: descriptive statistics), consistent on simple plots and summary statistics, have evolved well beyond its original scope.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979640e1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6012f8d6",
   "metadata": {},
   "source": [
    "### Elements of Structured Data (Data Types)\n",
    "\n",
    "__Numeric:__ Data that are expressed on a numeric scale.\n",
    "\n",
    "- __Continous ->__ Data that can take on any value in an interval (Synonyms: interval, float, numeric)\n",
    "\n",
    "- __Discrete ->__ Data that can take on only integer values, such as counts (Synonyms: integer, count)\n",
    "\n",
    "\n",
    "\n",
    "__Categorical:__ Data that can take on only a specific set of values representing a set of possible categories (Synonyms: enums, enumerated, factors, nominal).\n",
    "\n",
    "- __Binary ->__ A special case of categorical data with just two categories of values, e.g.: 0/1, true/false (Synonyms: dichotomous, logical, indicator, boolean)\n",
    "\n",
    "- __Ordinal ->__ Categorical data that has an explicit ordering (Synonyms: ordered factor).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c2142",
   "metadata": {},
   "source": [
    "### Rectangular Data\n",
    "\n",
    "__Dataframe:__ Rectangular data (like a spreadsheet) is the basic data structure for statistical (and machine learning) models.\n",
    "\n",
    "__Feature:__ A column within a table is commonly referred to as a feature (Synonyms: attribute, input, predictor, variable).\n",
    "\n",
    "__Record:__ A row within a table is commonly referred to as a record (Synonyms: case, example, instance, observation, pattern, sample)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74b57f8",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "- [SciPy](https://docs.scipy.org/doc/scipy/reference/index.html#scipy-api)\n",
    "\n",
    "- [statsmodels](https://www.statsmodels.org/stable/api.html)\n",
    "\n",
    "- [wquantiles](https://pypi.org/project/wquantiles/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import trim_mean   # conda install scipy\n",
    "from statsmodels import robust      # conda install -c conda-forge statsmodels \n",
    "import wquantiles                   # pip install wquantiles\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c714517a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Estimates of Location\n",
    "\n",
    "An estimate of where most of the data is located (i.e.: its central tendency)\n",
    "\n",
    "- __Mean:__ The sum of all values divided by the number of values (a.k.a.: average)\n",
    "\n",
    "- __Weighted mean:__ The sum of all values times a weight divided by the sum of the weights (a.k.a.: weighted average)\n",
    "\n",
    "- __Trimmed mean:__ The average of all values after dropping a fixed number of extreme values (a.k.a.: truncated mean).\n",
    "\n",
    "- __Median:__ The value such that one-half of the data lies above and below (a.k.a.: 50th percentile)\n",
    "\n",
    "- __Weighted median:__ The value such that the one-half of the sum of the weights.\n",
    "\n",
    "--\n",
    "\n",
    "- __Percentile:__ The value such that _P_ percent of the values take on this value or less and (100 - _P_) percent take on this value or more (a.k.a.: quantile).\n",
    "\n",
    "- __Robust:__ Not sensitive to extreme values (a.k.a.: resistant).\n",
    "\n",
    "- __Outlier:__ A data value that is very different from most of the data (a.k.a.: extreme value).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f681c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = pd.read_csv('./datasets/state.csv')\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean\n",
    "\n",
    "mean = state['Population'].mean()\n",
    "\n",
    "print('Mean:', mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dccf8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted mean\n",
    "\n",
    "mean = state['Murder.Rate'].mean()\n",
    "\n",
    "wmean = np.average(state['Murder.Rate'], weights=state['Population'])\n",
    "\n",
    "print('Mean:', mean, '\\nWeighted mean:', wmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da583bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trimmed mean\n",
    "\n",
    "tmean = trim_mean(state['Murder.Rate'], 0.1)\n",
    "\n",
    "print('Trimmed mean:', tmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median \n",
    "\n",
    "median = state['Population'].median()\n",
    "\n",
    "print('Median:', median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b049ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted median\n",
    "\n",
    "median = state['Murder.Rate'].median()\n",
    "\n",
    "wmedian = wquantiles.median(state['Murder.Rate'], weights=state['Population'])\n",
    "\n",
    "print('Median:', median, '\\nWeighted median:', wmedian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93148e56",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Estimates of Variability\n",
    "\n",
    "Variability measures whether the data values are tightly clustered or spread out. These estimators are not equivalent!!!\n",
    "\n",
    "- __Deviations:__ The difference between the observed values and the estimate of location (a.k.a.: errors, residuals).\n",
    "\n",
    "- __Mean absolute deviation:__ The mean of the absolute values of the deviations from the mean (a.k.a.: l1-norm, Manhattan norm).\n",
    "\n",
    "- __Variance:__ The sum of squared deviations from the mean divided by `n - 1` where _n_ is the number of data values (a.k.a.: mean-squared-error).\n",
    "\n",
    "- __Standard deviation:__ The square root of the variance.\n",
    "\n",
    "--\n",
    "\n",
    "- __Order statistics:__ Metrics based on the data values sorted from smallest to biggest (a.k.a.: ranks).\n",
    "\n",
    "- __Range:__ The difference between the largest and the smallest value in a data set.\n",
    "\n",
    "- __Interquartile range:__ The difference between the 75th percentile and the 25th percentile (a.k.a.: IQR).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a19d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deviations \n",
    "\n",
    "state['dev_population'] = state['Population'].mean() - state['Population']\n",
    "\n",
    "state['dev_murder'] = state['Murder.Rate'].mean() - state['Murder.Rate']\n",
    "\n",
    "print('Population deviation:', state['dev_population'].sum(), '\\nMurder Rate deviation:', state['dev_murder'].sum())\n",
    "\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8115d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute deviation\n",
    "\n",
    "state['mean_dev_population'] = abs(state['Population'].mean() - state['Population'])\n",
    "\n",
    "state['mean_dev_murder'] = abs(state['Murder.Rate'].mean() - state['Murder.Rate'])\n",
    "\n",
    "print('Population mean absolute deviation:', state['mean_dev_population'].sum() / len(state['mean_dev_population']),\n",
    "      '\\nMurder Rate absolute deviation deviation:', state['mean_dev_murder'].sum() / len(state['mean_dev_murder']))\n",
    "\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad366b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance\n",
    "\n",
    "state['var_population'] = (state['Population'].mean() - state['Population'])**2\n",
    "\n",
    "variance = state['var_population'].sum() / (len(state['var_population']) - 1)\n",
    "\n",
    "print('Variance:', variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6b9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation\n",
    "\n",
    "std_dev = state['Population'].std()\n",
    "\n",
    "print('Standard deviation:', std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c59ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order statistics (spread of sorted data)\n",
    "\n",
    "feature = 'Population'\n",
    "\n",
    "order_data = state[['State', feature]].sort_values(by=[feature]).reset_index(drop=True)\n",
    "\n",
    "order_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fcb1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range\n",
    "\n",
    "population_range = state['Population'].max() - state['Population'].min()\n",
    "\n",
    "murder_range = state['Murder.Rate'].max() - state['Murder.Rate'].min()\n",
    "\n",
    "print('Population range:', population_range, '\\nMurder Rate range:', murder_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd16683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentiles (it is NOT a data point)\n",
    "\n",
    "per_75 = state['Population'].quantile(0.75)\n",
    "\n",
    "per_25 = state['Population'].quantile(0.25)\n",
    "\n",
    "per_50 = state['Population'].quantile(0.50)   # == Median\n",
    "\n",
    "print('Percentile 75th:', per_75, '\\nPercentile 25th:', per_25, '\\nPercentile 50th:', per_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632ed2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interquartile range\n",
    "\n",
    "iqr = per_75 - per_25\n",
    "\n",
    "print('Interquartile range:', iqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09247663",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ironhack]",
   "language": "python",
   "name": "conda-env-.conda-ironhack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
